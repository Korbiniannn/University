{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praktikum : Classification - MNIST\n",
    "\n",
    "**Docker im K019:**\n",
    "- Laden Sie das Jupyter Notebook von Moodle in einen ML1-Praktikums-Ordner in Ihrem User-Ordner. \n",
    "- Geben Sie im Terminal ein: \"docker_start_ml1_gpu\". Dadurch wird ein Skript aufgerufen, das einen Docker-Container für Sie baut. Das Terminal bleibt offen, wechselt nun allerdings in einen Terminal des Docker-Containers.\n",
    "- Öffnen Sie den angegebenen localhost:8888-Link mit Token im Browser. Ein Jupyter Notebook sollte sich öffnen. Unter dem Ordner \"host\" finden Sie Ihr Homedirectory und auch das Jupyter-Notebook für das Praktikum. \n",
    "- Zum Ende des Praktikums speichern Sie Ihre Fortschritte, und beenden dann den Docker Container mit der Eingabe von \"exit\" im Terminal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir arbeiten wieder mit dem MNIST Datensatz wie im 3. Praktikum. \n",
    "Der erste Teil ist \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO\n",
    "binäre Klassifikation: \n",
    "- Logistic Regression: Teilt den Raum durch eine lineare Hyperflächen in disjunkte Bereiche für die einzelnen Klassen mit dem Ziel, Cross-Entropy Loss zu minimieren. \n",
    "- SVM für binäre Klassifizierung: Hier wird der Raum ebenfalls durch Hyperflächen in disjunkte Bereiche geteilt, allerdings dieses mal mit dem geometrischen Ziel, mit der Hyperfläche den Margin zwischen den Klassen zu maximieren. \n",
    "- Classification Tree: Clustert die Instances mit einem binary tree, wobei bei jedem Split die impurity minimiert wird. Für jede Instance wird die häufigste Klasse im Leaf vorhergesagt\n",
    "- Random Forest Classification: Ein Ensemble aus Classification Trees; vorhergesagt wird entweder die am häufigsten vorhergesagte Klasse oder der Wahrscheinlichkeitsvektor wobei die Wahrscheinlichkeit jeder Klasse die Häufigkeit der Vorhersage dieser Klasse unter allen Vorhersagen ist. \n",
    "- AdaBoost für binäre Klassifizierung: Ein additive boosting Model aus Classification Trees, das den exponentiellen Fehler minimiert. Jedes weitere Modell wird darauf trainiert, die Fehler der bisherigen Vorhersagen auszugleichen. \n",
    "- XGBoost: Ein Boosting Ensemble aus Bäumen mit zusätzlicher Regularisierung, welche die Größe der Bäume bestraft. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Welche Modelle könnten Sie verwenden, um die Klassifikation von allen 10 Ziffern durchzuführen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO\n",
    "10-Klassen Klassifizierung.\n",
    "- Softmax Regression\n",
    "- Kombination von mehreren SVMs, e.g. 10 SVMs für die Klassifizierung aller Klassen. (one vs all) \n",
    "- Classification Tree\n",
    "- Random Forest Classification\n",
    "- SAMME\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Führen Sie den folgenden Code aus, um die Daten zu laden:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import der notwendigen Dependencies\n",
    "import os\n",
    "#zum Entpacken von Dateien:\n",
    "import tarfile\n",
    "#zum Herunterladen von Dateien:\n",
    "import urllib.request\n",
    "#zum Bearbeiten von \"DataFrames\"\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MNIST_PATH = os.path.join(\"datasets\", \"MNIST\")\n",
    "\n",
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1, as_frame=False, data_home=MNIST_PATH)\n",
    "    mnist.target = mnist.target.astype(np.int64)\n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original', data_home=MNIST_PATH)\n",
    "\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test-Splitting:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train ist ein numpy ndarray der shape (56000, 784). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Trainieren von Binary Classifiers - Erweiterung von Praktikum 3\n",
    "\n",
    "Wir starten wie in Praktikum 3 und trainieren auf MNIST zunächst binären Classifier - dieses Mal mehr als bisher. Wir machen wieder aus den alten Labels 0,1,2, ..., 9 neue Labels y_train_4 bzw. y_test_4, welche den Wert 1 haben für y=4 und 0 sonst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_4 = (y_train == 4)*1\n",
    "y_test_4 = (y_test == 4)*1\n",
    "\n",
    "print(y_train[:5], y_train_4[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie zuvor trainieren wir auf MNIST mit den neuen Labels ein Logistic Regression Modell log_reg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "\t\n",
    "log_reg = LogisticRegression(solver = 'liblinear')\n",
    "log_reg.fit(X_train, y_train_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laden Sie den trainierten LinearSVC aus Praktikum 3 mit joblib.load. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "filename = os.path.join(MNIST_PATH , 'SVM_Classifier_MNIST.sav')\n",
    "svm_clf = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier machen wir nun weiter mit zusätzlichen Modellen:\n",
    "\n",
    "Trainieren Sie einen Random Forest Classifier für den obigen ML task. Nennen Sie drei Baum-Spezifische Hyperparameter, die overfitting vermeiden. Beschreiben Sie diese in der nächsten Zelle.  Verwenden Sie Grid Search [GirdSearchCV](https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html), um gute Hyperparameter für diesen Classifier zu finden. Benennen Sie den best_estimator_ mit forest_clf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainieren Sie nun ein entsprechendes [AdaBoost Modell]((https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)) basierend auf einem [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict_proba) \n",
    "\n",
    "Achtung: Da Sie wieder mit einem DecisionTreeClassifier arbeiten, müssten Sie wieder die Hyperparameter für DecisionTrees beachten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bewerten der Modelle\n",
    "\n",
    "\n",
    "**Fleißaufgabe, falls Sie Zeit haben, sonst springen Sie eins weiter:** \n",
    "Lassen Sie sich zunächst mittels .score() die mittlere accuracy = Genauigkeit der oben trainierten Modelle auf dem test set ausgeben und speichern Sie diese in einem Dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hier auf jeden Fall weiter machen**:\n",
    "Nun wollen wir mit etlichen statistischen Methoden die oben angelegten Modelle log_reg, svm_clf, forest_clf, ada_clf miteinander vergleichen. \n",
    "Um ums mit Schleifen etwas Zeit sparen zu können, legen wir zunächste in Dictionary dict_models an, in dem wir die Modelle speichern. \n",
    "\n",
    "Legen Sie dann ein Dictionary dict_test_predictions an, in dem Sie die .predict() Vorhersagen (also die Klassen, nicht die Wahrscheinlichkeiten) der vier Modelle auf den Testdaten abspeichern. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anlegen eines Dictionarys aus den Modellen\n",
    "dict_models = \n",
    "\n",
    "# Anlegen eines Dictionarys aus Modellen und ihren Vorhersagen\n",
    "dict_test_predictions = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legen Sie drei neue Dictionaries namens \n",
    "- dict_precisions\n",
    "- dict_recalls\n",
    "- dict_f1\n",
    "an, in denen Sie die Precisions, Recalls bzw. F1-Scores der einzelnen Modelle abspeichern. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print('Precisions:')\n",
    "#TODO\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print('Recalls:')\n",
    "#TODO\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print('F1-scores:')\n",
    "#TODO\n",
    "\n",
    "\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Welches Modell würden Sie verwenden, wenn eine falsche Klassifizierung einer 5 oder 7 oder 1 als 4 Sie sehr viel Geld kosten würde?\n",
    "2. Welches Modell würden Sie verwenden, wenn es schlimme Auswirkungen hätte, wenn eine 4 nicht erkannt wird?\n",
    "3. Welches Modell würden Sie verwenden, wenn Sie ein ausgewogenes Modell haben wollen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. #TODO: \n",
    "2. #TODO: \n",
    "3. #TODO: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision-Recall-Curve\n",
    "\n",
    "Wir wollen nun die Precision_Recall-Curve für die Testdaten zeichnen. \n",
    "\n",
    "Erinnerung: Für ein Modell (mit fixem Threshold für die Wahrscheinlichkeit, zum Beispiel 50%, ab dem man eine Instance als positiv klassifiziert), gibt es einen Wert für Precision, und einen Wert für Recall. \n",
    "\n",
    "Lässt man allerdings den Threshold variieren (zum Beispiel weil man lieber auf Nummer sicher gehen will bei einer positiven Klassifizierung und erst ab 80% Wahrscheinlichkeit etwas als positiv klassifizieren lässt), so ändern sich entsprechend Recall und Precision Werte. Nun kann man den Threshold kontinuierlich von 0 bis 100% variieren - das ändert nicht die Wahrscheinlichkeitsvektoren, die das Modell prognostiziert, aber die Klassen, die auf Basis dieses Wahrscheinlichkeitsvektors für jede Instance festgelegt werden. \n",
    "\n",
    "Plottet man nun Recall und Precision für unterschiedliche Thresholds zwischen 0 und 100%, erhält man die Precision-Recall-Curve. \n",
    "\n",
    "Daher braucht precision_recall_curve als Input die vorhergesagten Wahrscheinlichkeiten des positiven Labels, nicht die vorhergesagten Klassen (die ändern sich ja, wenn man den Threshold variiert)! Also legen wir uns in der nächsten Zelle zunächst ein Dictionary dict_test_predictions_proba an, das für jedes Modell die vorhergesagten Wahrscheinlichkeitsvektoren (mit .predict_proba()) für das Test Set abspeichert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Berechnen der (2-dimensionalen) Wahrscheinlichkeitsvektoren (für negative und positive Klasse)\n",
    "dict_test_predictions_proba = dict()\n",
    "\n",
    "for model in dict_models: \n",
    "    dict_test_predictions_proba[model] = dict_models[model].predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun berechnen Sie für jedes Modell aus den oben ausgerechneten Wahrscheinlichkeiten die Precision-Recall-Curve, indem Sie y_test_4 vergleichen mit den Wahrscheinlichkeiten der positiven Klasse, die Sie oben berechnet haben (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html). Hinweis: die Wahrscheinlichkeit der positiven Klasse (1) ist der zweite Eintrag in den Wahrscheinlichkeitsvektoren (der erste ist die Wahrscheinlichkeit der negativen Klasse 0). \n",
    "\n",
    "Erinnerung: precision_recall_curve gibt ein Tupel zurück, das aus einer Liste der precision-Werte, einer Liste der recall-Werte, und einer LIste der zugehörigen threshold-werte ausgibt. Mit diesen Werten kann man plotten.\n",
    "\n",
    "Legen Sie sich zum Speichern der zu plottenden Daten für die vier Modelle ein Dictionary namens dict_precisions_recalls an, in dem Sie für jedes Modell precision, recall und threshold in einer Liste abspeichern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Berechnen der precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "dict_precisions_recalls = dict()\n",
    "\n",
    "for model in dict_test_predictions_proba: \n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotten Sie nun die Precision-Recall Curves für alle Modelle in einem Plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zeichnen der Precision-Recall Curve mit plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welches der Modelle ist hier das Beste? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC curves\n",
    "\n",
    "So ähnlich wie man die Precision Recall Curve erhält, erhält man auch die ROC Curve: hier berechnet man True Positive Rate und False Positive Rate für verschiedene Thresholds zwischen 0 und 100% und plottet die sich ergebende Kurve für die Modelle. \n",
    "\n",
    "Zur Erinnerung:\n",
    " \n",
    "True positive rate = Instances, die als positiv eingestuft werden und tatsächlich positiv sind / (alle instances, die tatsächlich positiv sind) = instances mit prediction 1 und y_test_4=1 / instances mit y_test_4=1\n",
    "\n",
    "False positive rate = Instances, die als positiv eingestuft werden und tatsächlich negativ sind / (alle instances, die tatsächlich negativ sind) = instances mit prediction 1 und y_test_4=0 / instances mit y_test_4=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeichnen Sie die ROC Curve (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) für alle Modelle mit variierenden Thresholds und markieren den Punkt, den log_reg (mit dem fixen Threshold!) auf der ROC Curve für Logistic Regression einnimmt, indem Sie den oben berechneten Punkt einzeichnen. Hinweis: roc_curve nimmt als Vorhersage des Modells wiederum die Wahrscheinlichkeit der positiven Klasse, wie bei precision_recall_curve. \n",
    "\n",
    "Legen Sie sich hierzu zunächst wie zuvor ein Dictionary an, das für alle vier Modelle das Tupel (fpr, tpr, threshold) abspeichert, das sie als Ergebnis von roc_curve erhalten. \n",
    "\n",
    "Plotten Sie dann die ROC-Curves aus diesen Daten für alle Modelle, indem Sie fpr vs tpr plotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "dict_roc_values = dict()\n",
    "for model in dict_models:\n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausweiten von SVMs auf 10 Klassen\n",
    "\n",
    "SVM ist klassischerweise ein binary classifier. Kann man diesen in einen multiclass classifier umwandeln? Antwort: ja! \n",
    "\n",
    "1. Möglichkeit: Trainiere für jeweils zwei der Klassen (also 0 und 1, 0 und 2, 0 und 3, ... , 1 und 2, 1 und 3, etc) einen SVM Classifier, der für jedes Bild ausgibt, in welcher der zwei Klassen es wahrscheinlicher liegt. Kombiniere die Classifiers (das sind sehr viele, genauer gesagt 2 aus 10!), indem man jedes Bild x der Klasse zuordnet, in die es die meisten SVM Classifier gesteckt hätten. Solch einen Classifier nennt man **OneVsOne-Classifier**; in Scikit-Learn: \n",
    "```python\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "ovo_clf = OneVsOneClassifier(SVM())\n",
    "```\n",
    "Nachteil: Die Trainingszeit multipliziert sich um ein vielfaches!\n",
    "2. Möglichkeit: \n",
    "Trainiere für jede der Klassen 0,1,..., 9 einen eigenen SVM-Classifier wie oben, der nur aussagt, ob ein Bild in diese Klasse gehört oder nicht. Wenn mehrere Classifier das Bild ihrer Klasse zuordnen würden (z.B. 8 und 9), dann gewinnt der SVM Classifier, der sich bei seiner Entscheidung sicherer ist, d.h. bei dem das Bild weiter weg ist von der Decision Boundary.Solch einen Classifier nennt man **OneVsAll-Classifier**, oder **OneVsRest-Classifier**. in Scikit-Learn:\n",
    "```python\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "ovo_clf = OneVsRestClassifier(SVM())\n",
    "```\n",
    "In den oben genannten OneVsXXXClassifiers kann man anstelle von SVM auch andere binary classifiers verwenden. \n",
    "\n",
    "Nachteil: hier ist die Trainingsdauer immer sehr viel länger als wenn man einfach ein Modell benutzt, das multiclass classification natürlicherweise kann, wie z.B. Logistic Regression, oder Random Forests. \n",
    "\n",
    "Für diese beiden Modelle könnte man die obigen classifications ganz leicht auch für alle Zahlen 0 bis 9 durchführen, was wir hier aus Zeitgründen aber nicht mehr durchführen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel für multiclass classification: KNN Classification\n",
    "\n",
    "KNN, oder \"K nearest neighbor classification\", merkt sich alle Trainingsdaten, und vergleicht eine neue instance mit den K im feature space nächstgelegenen Trainingsdaten, sieht sich an, welche Klasse die meisten dieser K nearest neighbors haben, und prognostiziert diese Klasse für die neue instance. \n",
    "\n",
    "Trainieren Sie einen KNN Classifier für die vollen MNIST Daten und berechnen Sie die Accuracy des Modells auf den Test-Daten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Würden Sie KNN Classification für ein Trainingsset von 1 Mio. Trainingsdaten verwenden? Warum bzw. warum nicht?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: "
   ]
  },
  {
   "attachments": {
    "KNN_LogReg.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgabe: \n",
    "\n",
    "Betrachten Sie die folgenden Daten: Was ist die Accuracy auf den Trainigsdaten mit 3NN-Classification und mit 1NN-Classification, wenn für die Prognose eines jeden Trainigspunkts auch dieser selbst noch im gemerkten Trainingsdatenset ist?\n",
    "\n",
    "![KNN_LogReg.png](attachment:KNN_LogReg.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: \n",
    "- 3NN: \n",
    "- 1NN: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Importance des Random Forest Classifier\n",
    "\n",
    "Der Random Forest Classifier hat nicht nur den Vorteil, dass er schnell und gut und für multiclass classification geeignet ist, sondern auch den Vorteil, dass man sich die Wichtigkeit der einzelnen Input-Features ausgeben lassen kann. Dies bentut man in der Realität oft, um erst mal die Features, die man hat, besser zu verstehen, und evtl etwas auszudünnen, um nur mit den wirklich relevanten Features ein anderes ML Modell zu trainieren. \n",
    "\n",
    "Lassen Sie sich für den oben trainierten Random Forest Classifier, der eine 4 erkennt, die feature importance ausgeben!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = #TODO\n",
    "\n",
    "print(feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir plotten nun die Feature Importance als 28x28-Bild mit .imshow(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_image = feature_imp.reshape(28,28)\n",
    "plt.imshow(importance_image, cmap=mpl.cm.hot)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction und Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Die MNIST Bilder haben 28x28 pixel, entsprechen also 784-dimensionalen Vektoren. Verwenden Sie PCA (https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html), um die MNIST Bilder von 784 Dimensionen auf weniger zu komprimieren. Dabei wollen wir 95% der Varianz in den Daten erhalten. Finden Sie heraus, auf wie viele Dimensionen in diesem Fall projiziert wird. Nennen Sie die komprimierten Daten X_reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnen Sie die \"decompressed\" Version der komprimierten Daten X_reduced und nennen Sie diese Daten X_recovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wählen Sie eine beliebige Instance von X_recovered, reshapen Sie diese als 28x28 Bild, und lassen Sie es sich anzeigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Method: Clustering\n",
    "\n",
    "Nun verwenden wir Clustering, um die MNIST Bilder in 10 verschiedene Cluster zu unterteilen. Vorteil: Diese Methode kann man auch zum klassifizieren von ungelabelten Daten verwenden! Da clustering keine Labels verwendet (unsupervised), und wir nicht mit \"wirklichen\" Ergebnissen Vergleichen können, brauchen wir hier auch nicht in train und test set zu unterteilen. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verwenden Sie zuerst das K-Means Modell kmeans10 für K=10 (https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html), und verwenden Sie alle MNIST daten X, nicht nur die Trainings-Daten. Lassen Sie sich die Cluster Centers mit cluster_centers_ ausgeben, und berechnen Sie die Silhouette Score. Ist dieser Wert gut? #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freiwillige Zusatz-\"Herumspiel\"-Aufgabe: Vergleichen Sie die Ground Truth Labels mit den jeder Instance zugeorndeten Cluster-Nummer, und geben Sie die Matrix aus (z.B. als DataFrame), die angibt, wie viele true label j instances einem cluster i zugeordnet werden. Würden Sie bei diesem Ergebnis Clustering verwenden, um eine Klassifizierung durchzuführen, wenn Sie auch Labels haben? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anscheinend klappt das Clustering bei den Bilddaten sehr schlecht! Dies kann man folgendermaßen erklären: Betrachten Sie zwei Bilder der gleichen handgeschriebenen Zahl 8, wobei aber die Ziffer im einen Fall rechtsbündig, im anderen Fall linksbündig im Bild liegt. Die Vorhersage sollte dieselbe sein, doch in beiden Bildern sind ganz andere Pixel hell, das heißt die Werte der einzelnen Features ganz unterschiedlich! Im Feature Space wären diese beiden Bilder derselben Zahl also sehr weit auseinander - eventuell weiter auseinander als eine 8 und eine 4, die zufällig den selben Bildausschnitt einnehmen! Das ist der Grund, weshalb ein einzelnes Feature bei den MNIST Bildern wenig Aussagekraft hat, und die Cluster im Feature Space auch nicht unbedingt viel damit zu tun haben, welche Ziffern abgebildet sind. \n",
    "\n",
    "Wir merken also: die Methoden, die wir kennen gelernt haben, funktionieren manchmal, aber nicht immer! Es hängt alles von den Daten und ihrer Beschaffenheit ab, was funktioniert, und was nicht, und manchmal sind Methoden für gewissen Daten einfach schlecht geeignet, wie hier Clustering für die Klassifizierung von handgeschriebenen Ziffern. Manche Sachen kann mich sich durch \"gesunden Menschenverstand\" und Kenntnis der Theorie nicht nur erklären, sondern vorab herleiten, und sich damit viel Zeit sparen. Es bringt also durchaus viel für die praktische Anwendung, die Wirkungsweise von Modellen wirklich durchdrungen zu haben! \n",
    "\n",
    "Nachdem wir uns nun Gedanken gemacht haben, warum einzelne Features und Abstände im Feature Space bei Bildern nicht unbedingt so aussagekräftig sind wie es ein einzelnes Feature beim Housing-Dataset war (z.B. median income), können wir uns die Frage stellen, ob die obigen Methoden überhaupt geeignet sind für die Auswertung von Bilddaten... \n",
    "\n",
    "Z.B.: Wollen wir Bilder von Katzen und Hunden klassifizieren, kann es sein, dass die Tiere nicht immer zentral und in der gleichen Größe abgebildet sind wie hier bei den MNIST Bildern. Ein Kätzchen im rechten oberen Eck und eine Katze links unten würden von einem der obigen Algorithmen wohl unterschiedlicher eingeschätzt werden als eine Katze und ein Hund am gleichen Ort und in der gleichen Größe... Wie können wir einer künstlichen Intelligenz beibringen, Verschiebungen im Bild nicht zu beachten, wenn dies jedoch bedeutet, dass ganz andere Features/Dimensionen die einander entsprechenden Werte haben?\n",
    "\n",
    "Dazu gibt es eine spezielle Klasse von neuronalen Netzen, die genau diese \"Translationsinvarianz\" von Bildern berücksichtigt. Convolution Neural Networks oder Transformer (btw: Transformer sind die Technologie hinter ChatGPT...)... mit diesen hätten wir auch die MNIST Bilder noch besser klassifizieren können als mit den obigen Methoden! Diese lernen wir im nächsten Semester...\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

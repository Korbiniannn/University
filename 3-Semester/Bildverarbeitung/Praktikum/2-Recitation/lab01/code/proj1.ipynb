{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 4476 Project 1: Image Filtering and Hybrid Images\n",
    "\n",
    "All projects in this course will be done with these iPython notebooks. These are convenient ways for you to quickly and easily interact with the code. A notebook contains many blocks of code, each of which can be run independently. You can run a cell with ctrl+enter or shift+enter (to move to the next cell).\n",
    "\n",
    "\n",
    "## Part 1: NumPy\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import load_image, save_image\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "image1 = load_image('../data/1a_dog.bmp')\n",
    "image2 = load_image('../data/1b_cat.bmp')\n",
    "\n",
    "# display the dog and cat images\n",
    "plt.figure(figsize=(3,3)); plt.imshow((image1*255).astype(np.uint8));\n",
    "plt.figure(figsize=(3,3)); plt.imshow((image2*255).astype(np.uint8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create filter\n",
    "\n",
    "You will first need to implement `create_Gaussian_kernel()` in `part1.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success -- kernel values are correct.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from part1 import my_imfilter, create_hybrid_image, create_Gaussian_kernel\n",
    "from unit_test import verify_gaussian_kernel\n",
    "\n",
    "cutoff_frequency = 7\n",
    "kernel = create_Gaussian_kernel(cutoff_frequency)\n",
    "\n",
    "# let's take a look at the filter!\n",
    "plt.figure(figsize=(4,4)); plt.imshow(kernel);\n",
    "\n",
    "## Verify that the Gaussian kernel was created correctly\n",
    "print(verify_gaussian_kernel(kernel, cutoff_frequency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply filter to image\n",
    "The next two functions you need to implement in this project can also be found in `part1.py`. Start by implementing `my_imfilter`, which takes both a filter and an image, and returns the filtered image. This code block will use your `my_imfilter` function to create and display a blurry version of image1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurry_image = my_imfilter(image1, kernel)\n",
    "\n",
    "plt.figure(); plt.imshow((blurry_image*255).astype(np.uint8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hybrid image\n",
    "Next, implement _create_\\__hybrid_\\__image_(), which takes two images and makes a hybrid image using the low frequency content from one image and the high frequency content from another by applying the Gaussian kernel you defined in `create_Gaussian_kernel()`.\n",
    "\n",
    "Experiment with the value of `cutoff_frequency` for each pair of images in `data/`. For each image pair, replace `cutoff_frequencies.txt` with the best cutoff frequency value you find. The value on line *i* of the text file should correspond to _i_-th image pair. This is an important step for Part 2! Feel free to also experiment with which image in each pair you grab the low frequencies from and which image you grab high frequencies from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Low frequencies values are correct.\n",
      "True\n",
      "Success! High frequencies values are correct.\n",
      "True\n",
      "Success! Hybrid image values are correct.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from utils import vis_image_scales_numpy\n",
    "\n",
    "from unit_test import (\n",
    "    verify_low_freq_sq_kernel_np,\n",
    "    verify_high_freq_sq_kernel_np,\n",
    "    verify_hybrid_image_np\n",
    ")\n",
    "low_frequencies, high_frequencies, hybrid_image = create_hybrid_image(image1, image2, kernel)\n",
    "\n",
    "## Verify that results are as expected\n",
    "print(verify_low_freq_sq_kernel_np(image1, kernel, low_frequencies))\n",
    "print(verify_high_freq_sq_kernel_np(image2, kernel, high_frequencies))\n",
    "print(verify_hybrid_image_np(image1, image2, kernel, hybrid_image))\n",
    "\n",
    "vis = vis_image_scales_numpy(hybrid_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(); plt.imshow((low_frequencies*255).astype(np.uint8));\n",
    "plt.figure(); plt.imshow(((high_frequencies+0.5)*255).astype(np.uint8));\n",
    "plt.figure(figsize=(20, 20)); plt.imshow(vis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image('../results/part1/low_frequencies.jpg', low_frequencies)\n",
    "save_image('../results/part1/high_frequencies.jpg', high_frequencies+0.5)\n",
    "save_image('../results/part1/hybrid_image.jpg', hybrid_image)\n",
    "save_image('../results/part1/hybrid_image_scales.jpg', vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: PyTorch \n",
    "\n",
    "Make sure you have specified a cutoff value in `cutoff_frequencies.txt` for each image pair in `data/` before executing the following blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from datasets import HybridImageDataset\n",
    "from models import HybridImageModel\n",
    "\n",
    "\n",
    "data_root = '../data' # if you're using additional data, make sure to change this to '../additional_data'\n",
    "cf_file = '../cutoff_frequencies.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model & dataset\n",
    "Implement `HybridImageModel` and `HybridImageDataset`, found in `models.py` and `datasets.py`, respectively.\n",
    "\n",
    "In the code documentation, you will see a term called \"batch size\", which we will discuss in later projects and lectures. For now, we are using the default value of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridImageModel()\n",
    "dataset = HybridImageDataset(data_root, cf_file)\n",
    "dataloader = torch.utils.data.DataLoader(dataset)\n",
    "\n",
    "data_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hybrid images\n",
    "This code block will iterate through pairs of images from your dataset and create a hybrid image using the low frequency content from one image and the high frequency content from another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[0;32m----> 2\u001b[0m     image_a, image_b, cutoff_frequency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_iter)\n\u001b[1;32m      3\u001b[0m     low_frequencies, high_frequencies, hybrid_image \u001b[38;5;241m=\u001b[39m model(image_a, image_b, cutoff_frequency)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# saves low frequencies, high frequencies, and hybrid image of each pair of images\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bildver/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/bildver/lib/python3.12/site-packages/torch/utils/data/dataloader.py:756\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[0;32m~/miniconda3/envs/bildver/lib/python3.12/site-packages/torch/utils/data/dataloader.py:691\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter)\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset)):\n",
    "    image_a, image_b, cutoff_frequency = next(data_iter)\n",
    "    low_frequencies, high_frequencies, hybrid_image = model(image_a, image_b, cutoff_frequency)\n",
    "    \n",
    "    # saves low frequencies, high frequencies, and hybrid image of each pair of images\n",
    "    torchvision.utils.save_image(low_frequencies, '../results/part2/%d_low_frequencies.jpg' % i)\n",
    "    torchvision.utils.save_image(high_frequencies+0.5, '../results/part2/%d_high_frequencies.jpg' % i)\n",
    "    torchvision.utils.save_image(hybrid_image, '../results/part2/%d_hybrid_image.jpg' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verify that the results are correct, with cutoff_frequency of 7\n",
    "from unit_test import (\n",
    "    verify_low_freq_sq_kernel_pytorch, \n",
    "    verify_high_freq_sq_kernel_pytorch,\n",
    "    verify_hybrid_image_pytorch\n",
    ")\n",
    "\n",
    "dataset = HybridImageDataset(data_root, cf_file)\n",
    "dataloader = torch.utils.data.DataLoader(dataset)\n",
    "image_a, image_b, cutoff_frequency = next(iter(dataloader))\n",
    "low_frequencies, high_frequencies, hybrid_image = model(image_a, image_b, cutoff_frequency)\n",
    "\n",
    "cutoff_freq = torch.Tensor([7])\n",
    "## On first dog/cat pair, verify that the Pytorch results are as expected\n",
    "print(verify_low_freq_sq_kernel_pytorch(image_a, model, cutoff_freq, low_frequencies))\n",
    "print(verify_high_freq_sq_kernel_pytorch(image_b, model, cutoff_freq, high_frequencies))\n",
    "## Verify that the Pytorch hybrid images are created correctly\n",
    "print(verify_hybrid_image_pytorch(image_a, image_b, model, cutoff_freq, hybrid_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid image timing comparison\n",
    "Here, we will compare the runtime of creating hybrid images using your NumPy implementation to using your PyTorch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "image1 = load_image('../data/1a_dog.bmp')\n",
    "image2 = load_image('../data/1b_cat.bmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing Part 1. Notice that we explicitly include `create_Gaussian_kernel()` in the timing of Part 1 but not Part 2. This is because the function is already being called (and therefore timed) inside the forward pass of `HybridImageModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "cutoff_frequency = 7\n",
    "kernel = create_Gaussian_kernel(cutoff_frequency)\n",
    "low_frequencies, high_frequencies, hybrid_image = create_hybrid_image(image1, image2, kernel)\n",
    "end = time.time() - start\n",
    "print('Part 1: {:.3f} seconds'.format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridImageModel()\n",
    "\n",
    "start = time.time()\n",
    "low_frequencies, high_frequencies, hybrid_image = model(image_a, image_b, torch.Tensor([cutoff_frequency]))\n",
    "end = time.time() - start\n",
    "print('Part 2: {:.3f} seconds'.format(end))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bildver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

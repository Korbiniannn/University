{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "# Setup for Keras\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras #requirement: keras 3\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"pytorch\"\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "print(tf.__version__) #requirement: >= 15\n",
    "\n",
    "# Where to save the models\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "MODEL_PATH = os.path.join(PROJECT_ROOT_DIR, \"models\")\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check GPU availability: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 1: MLP with Keras (MNIST)\n",
    "\n",
    "In this first practical we train a simple MLP on the Fashion MNIST data and check the training progress on TensorBoard.\n",
    "We experience the exploding gradient problem with deep MLPs first hand and try out learning rate schedules.  \n",
    "\n",
    "**Aim:** Get a basic understanding of MLPs and dimensions, activation functions, get to know the basic principles of Keras and monitor the training process with TensorBoard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split up the full train set and the train labels into a validation set `X_valid` (5000 instances) with validation labels `y_valid`  and a train set `X_train` (the rest) with labels `y_train`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out any way you want how many different classes there are in the Fashion MNIST data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing: Scale all inputs (test, train and validation set) to mean 0 and standard deviation 1 first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set the random seed for keras and np to 42 to make outputs stable across runs. \n",
    "\n",
    "Also, in case you run the code several times, precede these random seed settings by a clear_session() to make sure Keras doesn't screw anything up. \n",
    "\n",
    "Then, define a model for the **Fashion MNIST classification problem** using Keras Sequential API with all layers within `Sequential()`, which does the following: \n",
    "- first, turn the 2D-input into a vector (Flatten)\n",
    "- First hidden layer: 300 units, to set the initialization to HeNormal, use the keyword `kernel_initializer`, see [documentation](https://keras.io/api/layers/initializers/)\n",
    "- activation function for the first layer: LeakyReLU\n",
    "- Second hidden layer: 100 units, again set the initialization to HeNormal\n",
    "- activation function for the second layer: LeakyReLU\n",
    "- a classification layer (what does this have to look like?). Determine how many output neurons you need yourself! \n",
    "\n",
    "**Question:** Explain why He initialization is used and why it stabilizes training at least at the beginning! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** #TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How many parameters do you have in this not very deep NN? Derive the number by computation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** #TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your result by getting the model's summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the advantage of LeakyReLU\n",
    "- over the sigmoid function?\n",
    "- over ReLU?\n",
    "If you are not sure how to set the slope in the negative part, what could you do?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** #TODO\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model using SGD; additionally ask the model to output accuracy as a metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up TensorBoard for Monitoring the Training Process\n",
    "\n",
    "We want to log our training process and visualize it with TensorBoard to see if the models overfit or how well training works. \n",
    "\n",
    "\n",
    "Start TensorBoard with the below code and go to localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create log files for Tensorboard with the TensorBoard callback. \n",
    "First, we define the path of the log files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(PROJECT_ROOT_DIR, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define the Tensorboard callback.\n",
    "Also, define a Checkpoint so the model can be rolled back to the best one.\n",
    "\n",
    "Attention! Keras' ModelCheckpoint sometimes leads to erratic errors if the file already exists. Therefore (just in case you run this code several times) add some code that deletes the model if it exists before you define the checkpoints. \n",
    "\n",
    "Also: If Keras still gives you an error on the ModelCheckpoint callback, restart the kernel and try again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Fit the model by training for 5 epochs, using the tensorboard callback and the checkpoint callback. \n",
    "Then rollback to the best model by loading the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT NOTE: These trained models will not be used later on, which is why we don't save them. However, if you want, you can save all the trained models. \n",
    "\n",
    "Now we modify our model.\n",
    "Reset the random seeds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Model - Vanishing/Exploding Gradients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the above model a lot deeper (>60 Layers!) and compare the results. However, for deep models, computing the gradient can be instable: for 50 layers, computing the gradient boils down to using the chain rule at least 60 times! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, use the Sequential API of Keras using model.add to build the same model as above, with the following modification: \n",
    "- repeat the 100-unit-dense layer before the output layer 60 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "What is the number of trainable parameters now? Again, first use theory to arrive at a number before you check it with code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** #TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train the model with SGD and additional metric accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train it for 5 epochs, again with (only) the TensorBoard Callback, where we create a new log_dir path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model. What might be the problem? #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset random seeds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A theoretical exercise on MLPs\n",
    "\n",
    "**Question:**\n",
    "\n",
    "Suppose we have a shallow regression network with 1 input units, 2 hidden units with activation function=$\\sin$, 1 sigmoid output unit, with biases. \n",
    "- Draw the architecture. How many are there? \n",
    "- Write the pre-activation, activation and output for one input $x$ in terms of the weights and biases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** #TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:**\n",
    "\n",
    "Suppose you have a Feedforward Network for 5-class Classification and: \n",
    "- 10 input features, \n",
    "- one hidden layer with 100 units with ReLU activation (and biases)\n",
    "- a second hidden layer with 200 units with Parametric ReLU activation (and biases)\n",
    "- a third hidden layer with 50 units and SELU activation (and biases)\n",
    "- an output layer \n",
    "\n",
    "\n",
    "\n",
    "1. What does the output layer have to look like for 5-class classification?\n",
    "\n",
    "#TODO\n",
    "\n",
    "2. Fill out the x-es in the following table: \n",
    "\n",
    "#TODO\n",
    "\n",
    "\n",
    "|Layer|number of weights|number of biases|additional parameters|\n",
    "|:---|:---|:---|:---|\n",
    "|first layer|x|x|x|\n",
    "|second layer|x|x|x|\n",
    "|third layer|x|x|x|\n",
    "|output layer|x|x|x|\n",
    "\n",
    "3. Let $W_i, b_i$ be weight matrix and bias vector for the ith layer. Write the activations of all layers as function in the output vector of the layer below (denote the activations=outputs of layer i by $z_i$) \n",
    "   \n",
    "|Layer|Output|\n",
    "|:---|:---|\n",
    "|first layer|x|\n",
    "|second layer|x|\n",
    "|third layer|x|\n",
    "|output layer|x|\n",
    "   \n",
    "4. Write the output in terms of matrices and vectors for \n",
    "- only one instance\n",
    "- a mini-batch of size 128 called X\n",
    "and give the dimensions of all matrices and vectors you use! Here you can write $B_i$ for the matrix with the bias vector $b_i$ in each row.\n",
    "\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:**\n",
    "\n",
    "Suppose you have a Regression Feedforward Network to predict tomorrow's temperature, wind speed, an air pressure at midday. You have as input\n",
    "- 20 input features, \n",
    "- one hidden layer with 30 units \n",
    "- a second hidden layer with 40 units \n",
    "- an output layer \n",
    "where you have sigmoid activation functions for all hidden layers.\n",
    "\n",
    "1. What is the number of parameters of each layer?\n",
    "   #TODO\n",
    "\n",
    "2. If the network does not learn, what could be the problem?\n",
    "   #TODO\n",
    "\n",
    "3. What are the dimensions of the weight matrices $W_1, W_2, W_3$ and biases $b_1,b_2,b_3$?\n",
    "   #TODO\n",
    "\n",
    "4. Write down the formula for the output for a single input $x$.\n",
    "   #TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:**\n",
    "\n",
    "Suppose you have a MLP for binary classification without biases, and for some input $x$ we know the following about the last hidden layer: \n",
    "- all pre-activations in this hidden layer are negative, \n",
    "- the activation function of the hidden layer is a ReLU. \n",
    "What is the output for input $x$?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
